{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../DataSet/\"\n",
    "\n",
    "products = pd.read_csv(root_path + 'olist_products_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Inspect the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Products Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32951 entries, 0 to 32950\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   product_id                  32951 non-null  object \n",
      " 1   product_category_name       32341 non-null  object \n",
      " 2   product_name_lenght         32341 non-null  float64\n",
      " 3   product_description_lenght  32341 non-null  float64\n",
      " 4   product_photos_qty          32341 non-null  float64\n",
      " 5   product_weight_g            32949 non-null  float64\n",
      " 6   product_length_cm           32949 non-null  float64\n",
      " 7   product_height_cm           32949 non-null  float64\n",
      " 8   product_width_cm            32949 non-null  float64\n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 2.3+ MB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "product_id                      0\n",
      "product_category_name         610\n",
      "product_name_lenght           610\n",
      "product_description_lenght    610\n",
      "product_photos_qty            610\n",
      "product_weight_g                2\n",
      "product_length_cm               2\n",
      "product_height_cm               2\n",
      "product_width_cm                2\n",
      "dtype: int64\n",
      "\n",
      "Duplicate Product IDs:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial Products Dataset Info:\")\n",
    "print(products.info())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(products.isnull().sum())\n",
    "print(\"\\nDuplicate Product IDs:\")\n",
    "print(products['product_id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Handle missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped rows with missing product_id\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing product_id\n",
    "products = products.dropna(subset=['product_id'])\n",
    "print(\"Dropped rows with missing product_id\")\n",
    "\n",
    "# Fill missing product_category_name with 'Unknown'\n",
    "products['product_category_name'] = products['product_category_name'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed missing values in product_name_lenght with median\n",
      "Imputed missing values in product_description_lenght with median\n",
      "Imputed missing values in product_photos_qty with median\n",
      "Imputed missing values in product_weight_g with median\n",
      "Imputed missing values in product_length_cm with median\n",
      "Imputed missing values in product_height_cm with median\n",
      "Imputed missing values in product_width_cm with median\n"
     ]
    }
   ],
   "source": [
    "# Numerical columns: impute with median to maintain distribution\n",
    "numeric_cols = ['product_name_lenght', 'product_description_lenght', 'product_photos_qty',\n",
    "                'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']\n",
    "for col in numeric_cols:\n",
    "    products[col] = products[col].fillna(products[col].median())\n",
    "    print(f\"Imputed missing values in {col} with median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Ensure data type consistency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['product_id'] = products['product_id'].astype(str)\n",
    "products['product_category_name'] = products['product_category_name'].astype(str)\n",
    "for col in numeric_cols:\n",
    "    products[col] = products[col].astype(float)  # Use float to accommodate potential decimals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Validate numerical data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capped product_name_lenght at 99th percentile: 63.0\n",
      "Capped product_description_lenght at 99th percentile: 3274.5\n",
      "Capped product_photos_qty at 99th percentile: 8.0\n",
      "Capped product_weight_g at 99th percentile: 22537.5\n",
      "Capped product_length_cm at 99th percentile: 100.0\n",
      "Capped product_height_cm at 99th percentile: 69.0\n",
      "Capped product_width_cm at 99th percentile: 63.0\n"
     ]
    }
   ],
   "source": [
    "# Check for negative or unrealistic values\n",
    "for col in numeric_cols:\n",
    "    if (products[col] < 0).sum() > 0:\n",
    "        products.loc[products[col] < 0, col] = products[col].median()\n",
    "        print(f\"Replaced negative values in {col} with median\")\n",
    "\n",
    "    # Cap extreme outliers (e.g., > 99th percentile)\n",
    "    upper_limit = products[col].quantile(0.99)\n",
    "    products[col] = products[col].clip(lower=0, upper=upper_limit)  # Fixed syntax\n",
    "    print(f\"Capped {col} at 99th percentile: {upper_limit}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Check for duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 duplicate product IDs\n"
     ]
    }
   ],
   "source": [
    "products = products.drop_duplicates(subset=['product_id'], keep='first')\n",
    "print(f\"Removed {products['product_id'].duplicated().sum()} duplicate product IDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Creative Addition - Calculate product volume**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added product_volume_cm3 for size-related analysis\n"
     ]
    }
   ],
   "source": [
    "products['product_volume_cm3'] = (products['product_length_cm'] * \n",
    "                                  products['product_height_cm'] * \n",
    "                                  products['product_width_cm'])\n",
    "print(\"Added product_volume_cm3 for size-related analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7: Creative Addition - Flag heavy products**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added is_heavy flag for logistics insights\n"
     ]
    }
   ],
   "source": [
    "products['is_heavy'] = (products['product_weight_g'] > products['product_weight_g'].quantile(0.75)).astype(int)\n",
    "print(\"Added is_heavy flag for logistics insights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8: Save the cleaned dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products dataset cleaned and saved as './Data_Cleaned/cleaned_products_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "products.to_csv('./Data_Cleaned/cleaned_products_dataset.csv', index=False)\n",
    "print(\"Products dataset cleaned and saved as './Data_Cleaned/cleaned_products_dataset.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
